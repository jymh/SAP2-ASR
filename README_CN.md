# SAPÂ²-ASR: é¢å‘ä¸Šä¸‹æ–‡æ„ŸçŸ¥è‡ªåŠ¨è¯­éŸ³è¯†åˆ«çš„è¯­éŸ³æ„ŸçŸ¥é•¿ä¸Šä¸‹æ–‡å‰ªæä¸é›†æˆ

> **æ³¨æ„**ï¼šæœ¬ä»“åº“æ˜¯åŸºäº [ms-swift](https://github.com/modelscope/ms-swift) çš„ forkï¼Œå®ç°äº† SAPÂ²ï¼ˆSpeech-Aware Context Pruning with Speech-Driven Attention-based Poolingï¼Œè¯­éŸ³æ„ŸçŸ¥ä¸Šä¸‹æ–‡å‰ªæä¸è¯­éŸ³é©±åŠ¨æ³¨æ„åŠ›æ± åŒ–ï¼‰æ–¹æ³•ï¼Œç”¨äºä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼Œè¯¦è§æˆ‘ä»¬çš„[è®ºæ–‡](https://www.arxiv.org/pdf/2511.11139)ã€‚

<p align="center">
    <br>
    <img src="asset/banner.png"/>
    <br>
<p>
<p align="center">
<a href="https://www.arxiv.org/pdf/2511.11139">è®ºæ–‡</a> &nbsp ï½œ &nbsp <a href="https://github.com/jymh/SAP2-ASR">åŸå§‹ä»£ç </a> 
<br>
        <a href="README_CN.md">ä¸­æ–‡</a> &nbsp ï½œ &nbsp <a href="README.md">English</a> &nbsp
</p>

<p align="center">
<img src="https://img.shields.io/badge/python-3.10-5be.svg">
<img src="https://img.shields.io/badge/pytorch-%E2%89%A52.0-orange.svg">
<a href="https://github.com/modelscope/swift/blob/main/LICENSE"><img src="https://img.shields.io/github/license/modelscope/swift"></a>
</p>

## ğŸ“– ç›®å½•
- [ç®€ä»‹](#-ç®€ä»‹)
- [å®‰è£…](#%EF%B8%8F-å®‰è£…)
- [æ•°æ®é›†](#-æ•°æ®é›†)
- [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
- [ä½¿ç”¨è¯´æ˜](#-ä½¿ç”¨è¯´æ˜)
- [æ¨¡å‹æ¶æ„](#-æ¨¡å‹æ¶æ„)
- [å¼•ç”¨](#-å¼•ç”¨)
- [è®¸å¯è¯](#-è®¸å¯è¯)

## ğŸ“ ç®€ä»‹

**SAPÂ²ï¼ˆSpeech-Aware Context Pruning with Speech-Driven Attention-based Poolingï¼Œè¯­éŸ³æ„ŸçŸ¥ä¸Šä¸‹æ–‡å‰ªæä¸è¯­éŸ³é©±åŠ¨æ³¨æ„åŠ›æ± åŒ–ï¼‰** æ˜¯ä¸€ä¸ªç”¨äºä¸Šä¸‹æ–‡æ„ŸçŸ¥è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰çš„æ–°æ¡†æ¶ï¼Œèƒ½å¤ŸåŠ¨æ€å‰ªæå¹¶é›†æˆç›¸å…³çš„ä¸Šä¸‹æ–‡å…³é”®è¯ã€‚è¯¥æ–¹æ³•è§£å†³äº†åœ¨ç‰¹å®šé¢†åŸŸåœºæ™¯ï¼ˆå¦‚ä¼šè®®æ¼”è®²ï¼‰ä¸­åˆ©ç”¨é•¿ä¸Šä¸‹æ–‡ä¿¡æ¯çš„æŒ‘æˆ˜ï¼Œè¿™äº›åœºæ™¯ä¸­å¤§é‡æ¥è‡ªOCRçš„æ–‡æœ¬ä¸Šä¸‹æ–‡æ—¢åŒ…å«ç›¸å…³ä¿¡æ¯ï¼Œä¹ŸåŒ…å«å¤§é‡å™ªå£°ã€‚

### æ ¸å¿ƒç‰¹æ€§

- **è¯­éŸ³æ„ŸçŸ¥ä¸Šä¸‹æ–‡å‰ªæ**ï¼šåŠ¨æ€è¿‡æ»¤æ¥è‡ªOCRçš„æ–‡æœ¬ä¸Šä¸‹æ–‡ï¼Œä»…ä¿ç•™ä¸è¯­éŸ³å†…å®¹ç›´æ¥ç›¸å…³çš„å…³é”®è¯
- **è·¨æ¨¡æ€ä¸Šä¸‹æ–‡å‹ç¼©**ï¼šä½¿ç”¨è¯­éŸ³é©±åŠ¨æ³¨æ„åŠ›æ± åŒ–ï¼ˆSpeech-Driven Attention-based Poolingï¼‰å°†å¤§é‡æ–‡æœ¬è¾“å…¥å‹ç¼©ä¸ºç®€æ´çš„ã€ä¸è¯­éŸ³ç›¸å…³çš„ä¸Šä¸‹æ–‡åµŒå…¥
- **æœ€å…ˆè¿›çš„æ€§èƒ½**ï¼šåœ¨ SlideSpeech æ•°æ®é›†ä¸Šè¾¾åˆ° 7.71% çš„è¯é”™è¯¯ç‡ï¼ˆWERï¼‰ï¼Œåœ¨ LibriSpeech æ•°æ®é›†ä¸Šè¾¾åˆ° 1.12% çš„ WERï¼Œç›¸æ¯”éä¸Šä¸‹æ–‡åŸºçº¿ï¼Œåœ¨åå‘å…³é”®è¯è¯†åˆ«æ–¹é¢ç›¸å¯¹æå‡äº† 41.1%

### å®éªŒç»“æœ

- **SlideSpeech**ï¼šWER 7.71%ï¼ŒB-WER ç›¸æ¯”åŸºçº¿æå‡ 41.1%
- **LibriSpeech**ï¼šWER 1.12%
- åœ¨å¤§é‡ä¸Šä¸‹æ–‡è¾“å…¥æ¡ä»¶ä¸‹å…·æœ‰**é²æ£’çš„å¯æ‰©å±•æ€§**

### è¯†åˆ«ç¤ºä¾‹

ä¸‹å›¾å±•ç¤ºäº† SAPÂ² ä¸ä¹‹å‰æ–¹æ³•åœ¨ SlideSpeech æµ‹è¯•é›†ä¸Šçš„è¯†åˆ«ç¤ºä¾‹å¯¹æ¯”ã€‚çº¢è‰²æ–‡æœ¬è¡¨ç¤ºä¸“æœ‰åè¯çš„è¯†åˆ«é”™è¯¯ï¼Œç»¿è‰²é«˜äº®æ–‡æœ¬å±•ç¤ºäº† SAPÂ² æ‰€åšçš„ä¿®æ­£ã€‚

<p align="center">
  <img src="asset/figure1.jpg" alt="è¯†åˆ«ç¤ºä¾‹" width="800"/>
</p>

## ğŸ› ï¸ å®‰è£…

æœ¬é¡¹ç›®åŸºäº [ms-swift](https://github.com/modelscope/ms-swift)ã€‚å®‰è£…æ–¹æ³•å¦‚ä¸‹ï¼š

```shell
# å…‹éš†ä»“åº“
git clone https://github.com/jymh/SAP2-ASR.git
cd SAP2-ASR

# åˆ›å»º conda ç¯å¢ƒ
conda env create -f environment.yml

# æ¿€æ´»ç¯å¢ƒ
conda activate swift

# å®‰è£…åŒ…
pip install -e .
```

**ç¯å¢ƒè¦æ±‚ï¼š**
- Python >= 3.10
- PyTorch >= 2.0
- transformers >= 4.45
- librosaï¼ˆç”¨äºéŸ³é¢‘å¤„ç†ï¼‰

## ğŸ“Š æ•°æ®é›†

æœ¬é¡¹ç›®ä½¿ç”¨ä¸¤ä¸ªæ•°æ®é›†è¿›è¡Œè¯„ä¼°ï¼š**SlideSpeech** å’Œ **LibriSpeech**ã€‚ä¸¤ä¸ªæ•°æ®é›†éƒ½å¯ä»¥åœ¨ OpenSLR æ‰¾åˆ°ï¼Œæˆ–è€…æ‚¨å¯ä»¥ä»ä»¥ä¸‹æ¥æºä¸‹è½½ï¼š

### SlideSpeech

SlideSpeech æ˜¯ä¸€ä¸ªåŒ…å«å¹»ç¯ç‰‡çš„å¤§è§„æ¨¡éŸ³è§†é¢‘è¯­æ–™åº“ï¼ŒåŒ…å« 1,705 ä¸ªè§†é¢‘ï¼Œè¶…è¿‡ 1,000 å°æ—¶çš„éŸ³é¢‘ï¼Œå…¶ä¸­åŒ…æ‹¬ 473 å°æ—¶çš„é«˜è´¨é‡è½¬å½•è¯­éŸ³ã€‚

**ä¸‹è½½æ–¹å¼ï¼š**
1. **GitHub ä»“åº“**ï¼šä» [https://github.com/Mashiro009/slidespeech_dl.git](https://github.com/Mashiro009/slidespeech_dl.git) å…‹éš†å®˜æ–¹ä¸‹è½½è„šæœ¬
   ```shell
   git clone https://github.com/Mashiro009/slidespeech_dl.git
   cd slidespeech_dl
   bash run.sh
   ```

2. **OpenSLR**ï¼šå¯åœ¨ OpenSLR ç½‘ç«™è·å–

**æ•°æ®é›†è¯¦æƒ…ï¼š**
- ç½‘ç«™ï¼š[https://slidespeech.github.io/](https://slidespeech.github.io/)
- åŒ…å«åŒæ­¥çš„å¹»ç¯ç‰‡å’Œ OCR æå–çš„æ–‡æœ¬ä¸Šä¸‹æ–‡
- é€‚ç”¨äºä¸Šä¸‹æ–‡æ„ŸçŸ¥ ASR è¯„ä¼°

### LibriSpeech

LibriSpeech æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡è‹±è¯­æœ—è¯»è¯­éŸ³è¯­æ–™åº“ï¼Œæºè‡ª LibriVox é¡¹ç›®çš„æœ‰å£°è¯»ç‰©ã€‚

**ä¸‹è½½æ–¹å¼ï¼š**
1. **Hugging Face Datasets**ï¼šä½¿ç”¨ Hugging Face datasets åº“ç›´æ¥åŠ è½½
   ```python
   from datasets import load_dataset
   dataset = load_dataset("openslr/librispeech_asr")
   ```
   æˆ–è®¿é—®ï¼š[https://huggingface.co/datasets/openslr/librispeech_asr](https://huggingface.co/datasets/openslr/librispeech_asr)

2. **OpenSLR**ï¼šå¯åœ¨ OpenSLR ç½‘ç«™è·å–

**æ•°æ®é›†è¯¦æƒ…ï¼š**
- åŒ…å«çº¦ 1000 å°æ—¶çš„ 16kHz è‹±è¯­æœ—è¯»è¯­éŸ³
- åˆ†ä¸ºè®­ç»ƒé›†ï¼ˆtrain-cleanã€train-otherï¼‰ã€éªŒè¯é›†å’Œæµ‹è¯•é›†
- å¹¿æ³›ç”¨äº ASR ç³»ç»ŸåŸºå‡†æµ‹è¯•

**æ³¨æ„**ï¼šå¯¹äº LibriSpeechï¼Œæˆ‘ä»¬éµå¾ªè®ºæ–‡ä¸­çš„æ–¹æ³•ï¼Œä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†åŠ¨æ€æ„å»ºåç½®åˆ—è¡¨ï¼Œä½¿ç”¨ common5k è¯æ±‡è¡¨ä¹‹å¤–çš„å•è¯å’Œéšæœºé€‰æ‹©çš„å¹²æ‰°è¯ã€‚

### é¢„å¤„ç†æ•°æ®é›†å…ƒæ•°æ®

æˆ‘ä»¬åœ¨ Hugging Face ä¸Šæä¾›äº†é¢„å¤„ç†å¥½çš„æ•°æ®é›†å…ƒæ•°æ®ï¼ŒåŒ…å«ä¸º SAPÂ² æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å…³é”®è¯è®­ç»ƒæ•°æ®ã€‚å…ƒæ•°æ®åŒ…å«æ¥è‡ª SlideSpeech å’Œ LibriSpeech æ•°æ®é›†çš„ 109 ä¸‡è®­ç»ƒæ ·æœ¬ã€‚

**Hugging Face æ•°æ®é›†**ï¼š[https://huggingface.co/datasets/jymh/SAP2-ASR](https://huggingface.co/datasets/jymh/SAP2-ASR)

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ä½¿ç”¨ SAPï¼ˆè¯­éŸ³é©±åŠ¨æ³¨æ„åŠ›æ± åŒ–ï¼‰è®­ç»ƒ SAPÂ² æ¨¡å‹

ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºå¦‚ä½•åœ¨ SlideSpeech æ•°æ®é›†ä¸Šä½¿ç”¨ SAP æ± åŒ–è®­ç»ƒ SAPÂ² æ¨¡å‹ï¼š

```shell
# ä½¿ç”¨ SAP å‹ç¼©è¿›è¡Œå¤š GPU è®­ç»ƒ
NPROC_PER_NODE=8 CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 swift sft \
    --model "/path/to/qwen2-audio-instruct" \
    --model_type sap_qwen2_audio \
    --dataset "/path/to/slidespeech/train.json" \
    --val_dataset "/path/to/slidespeech/dev.json" \
    --save_steps 1000 \
    --save_total_limit 2 \
    --num_train_epochs 1 \
    --per_device_train_batch_size 32 \
    --per_device_eval_batch_size 32 \
    --max_length 4096 \
    --output_dir "/path/to/output" \
    --train_type lora \
    --freeze_llm false \
    --freeze_vit true \
    --freeze_aligner false \
    --lora_rank 8 \
    --sap_window_size 2 \
    --compressor_hidden_size 4096 \
    --num_attention_heads 4 \
    --deepspeed zero2
```

**å…³é”®å‚æ•°ï¼š**
- `--model_type sap_qwen2_audio`ï¼šä½¿ç”¨æ”¯æŒ SAP çš„ Qwen2-Audio æ¨¡å‹
- `--sap_window_size 2`ï¼šè¯­éŸ³é©±åŠ¨æ³¨æ„åŠ›æ± åŒ–çš„çª—å£å¤§å°
- `--compressor_hidden_size 4096`ï¼šå‹ç¼©å™¨çš„éšè—å±‚å¤§å°
- `--num_attention_heads 4`ï¼šæ± åŒ–ä½¿ç”¨çš„æ³¨æ„åŠ›å¤´æ•°é‡

### ä½¿ç”¨ SAPÂ² æ¨¡å‹è¿›è¡Œæ¨ç†

è®­ç»ƒå®Œæˆåï¼Œä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ¨ç†ï¼š

```shell
CUDA_VISIBLE_DEVICES=0 swift infer \
    --adapters /path/to/checkpoint-xxx \
    --infer_backend pt \
    --temperature 0 \
    --max_batch_size 4 \
    --val_dataset /path/to/test.json \
    --result_path /path/to/result.jsonl \
    --stream false \
    --sap_window_size 2 \
    --compressor_hidden_size 4096 \
    --num_attention_heads 4
```

## âœ¨ ä½¿ç”¨è¯´æ˜

### æ•°æ®å‡†å¤‡

SAPÂ² æ–¹æ³•è¦æ±‚ä¸Šä¸‹æ–‡å…³é”®è¯ï¼ˆä¾‹å¦‚æ¥è‡ª OCR æ–‡æœ¬ï¼‰ä½¿ç”¨ç‰¹æ®Šæ ‡è®° `<|startofcontext|>` å’Œ `<|endofcontext|>` è¿›è¡Œæ ¼å¼åŒ–ã€‚æ•°æ®æ ¼å¼ç¤ºä¾‹ï¼š

```json
{
  "messages": [
    {
      "role": "user",
      "content": "<audio>/path/to/audio.wav</audio>Transcribe speech to text according to keywords may appear in the utterance. Possible keywords are: <|startofcontext|>keyword1 keyword2 keyword3<|endofcontext|>"
    },
    {
      "role": "assistant",
      "content": "transcribed text"
    }
  ],
  "audios": "/path/to/audio.wav"
}
```

æ‚¨å¯ä»¥ä½¿ç”¨ `extract_predicted_keywords.py` å¤„ç†æ•°æ®å¹¶æ·»åŠ ä¸Šä¸‹æ–‡å…³é”®è¯ã€‚

### ä½¿ç”¨ SAP å‹ç¼©è¿›è¡Œè®­ç»ƒ

SAPï¼ˆè¯­éŸ³é©±åŠ¨æ³¨æ„åŠ›æ± åŒ–ï¼‰æœºåˆ¶ä½¿ç”¨è¯­éŸ³é©±åŠ¨æ³¨æ„åŠ›æ± åŒ–å‹ç¼©é•¿ä¸Šä¸‹æ–‡å…³é”®è¯ï¼š

```shell
swift sft \
    --model_type sap_qwen2_audio \
    --model "/path/to/qwen2-audio-instruct" \
    --dataset "/path/to/dataset" \
    --train_type lora \
    --sap_window_size 2 \
    --compressor_hidden_size 4096 \
    --num_attention_heads 4 \
    ...
```

### è¯„ä¼°

æ¨ç†å®Œæˆåï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æä¾›çš„è¯„ä¼°è„šæœ¬è¯„ä¼°ç»“æœï¼š

```shell
python evaluate_slidespeech_process.py --input_file /path/to/result.jsonl
```

## ğŸ—ï¸ æ¨¡å‹æ¶æ„

ä¸‹å›¾å±•ç¤ºäº† SAPÂ² çš„æ•´ä½“æ¶æ„ï¼š

<p align="center">
  <img src="asset/main_fig.jpg" alt="SAPÂ² æ¨¡å‹æ¶æ„" width="800"/>
</p>

æ ¸å¿ƒå®ç°ä½äº `swift/llm/model/sqp_models/modeling_sqp_qwen2audio.py`ï¼Œæ‰©å±•äº† `Qwen2AudioForConditionalGeneration`ï¼ŒåŒ…å«ï¼š

- **`Qwen2AudioSAPPoolingLayer`**ï¼šå®ç° SAPï¼ˆè¯­éŸ³é©±åŠ¨æ³¨æ„åŠ›æ± åŒ–ï¼‰ï¼ŒåŸºäºè¯­éŸ³ç‰¹å¾å‹ç¼©ä¸Šä¸‹æ–‡å…³é”®è¯
- **`SAP2Qwen2AudioForConditionalGeneration`**ï¼šå°† SAP å‹ç¼©é›†æˆåˆ° Qwen2-Audio æ¶æ„ä¸­çš„ä¸»æ¨¡å‹ç±»

SAP æ± åŒ–å±‚ä½¿ç”¨è¯­éŸ³åµŒå…¥å’Œä¸Šä¸‹æ–‡åµŒå…¥ä¹‹é—´çš„è·¨æ¨¡æ€æ³¨æ„åŠ›æ¥è®¡ç®—æ± åŒ–æƒé‡ï¼Œèƒ½å¤Ÿé«˜æ•ˆå‹ç¼©é•¿ä¸Šä¸‹æ–‡è¾“å…¥ï¼ŒåŒæ—¶ä¿ç•™ä¸è¯­éŸ³ç›¸å…³çš„ä¿¡æ¯ã€‚

## ğŸ“ å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº† SAPÂ²ï¼Œè¯·å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ï¼š

```bibtex
@article{rong2025speechaware,
  title={Speech-Aware Long Context Pruning and Integration for Contextualized Automatic Speech Recognition},
  author={Rong, Yiming and Zhang, Yixin and Wang, Ziyi and Jiang, Deyang and Zhao, Yunlong and Wu, Haoran and Zhou, Shiyu and Xu, Bo},
  journal={arXiv preprint arXiv:2511.11139},
  year={2025}
}
```


## ğŸ› è®¸å¯è¯

æœ¬æ¡†æ¶ä½¿ç”¨ [Apache License (Version 2.0)](https://github.com/modelscope/modelscope/blob/master/LICENSE) è¿›è¡Œè®¸å¯ã€‚æ¨¡å‹å’Œæ•°æ®é›†è¯·æŸ¥çœ‹åŸèµ„æºé¡µé¢å¹¶éµå®ˆå¯¹åº”çš„è®¸å¯è¯ã€‚

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset type 1\n",
    "\n",
    "整合关键词信息做语音识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "HOME_DIR = pathlib.Path(os.path.expanduser(\"~\"))\n",
    "\n",
    "def make_dataset(source_file, dst_file):\n",
    "    with open(source_file, 'r', encoding='utf8') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    INSTRUCTION_PROMPT = \"\"\"请结合以下可能出现的关键词，做语音转文本。可能出现的关键词为：{keywords}\"\"\"\n",
    "    # INSTRUCTION_PROMPT = \"\"\"Transcibe speech to text according to keywords may appear in the utterance. Possible key words are: {keywords}\"\"\"\n",
    "    # INSTRUCTION_PROMPT = \"\"\"Transcript Speech to Text: \"\"\"\n",
    "\n",
    "    INPUT_WRAPPER = \"\"\"<audio>{audio_path}</audio>{query}\"\"\"\n",
    "\n",
    "    if \"/data/rym/datasets/OpenSLR\" in data[0][\"audio_path\"]:\n",
    "        replace_path = \"/data/rym/datasets/OpenSLR\"\n",
    "    elif \"/nfs/speech/corpus/OpenSLR\" in data[0][\"audio_path\"]:\n",
    "        replace_path = \"/nfs/speech/corpus/OpenSLR\"\n",
    "    else:\n",
    "        raise ValueError(\"wrong input audio filepath\")\n",
    "\n",
    "    if \"text\" in data[0]:\n",
    "        label_name = \"text\"\n",
    "    elif \"transcript\" in data[0]:\n",
    "        label_name = \"transcript\"\n",
    "    else:\n",
    "        raise ValueError(\"wrong label name\")\n",
    "\n",
    "\n",
    "    dataset_to_write = []\n",
    "    for item in data:\n",
    "        keywords_lst = [s.lower() for s in item['keywords']]\n",
    "        query = INSTRUCTION_PROMPT.format(keywords=', '.join(keywords_lst))\n",
    "        audio_path = item[\"audio_path\"].replace(replace_path, str(HOME_DIR / \"datasets/OpenSLR\"))\n",
    "        assert pathlib.Path(audio_path).exists()\n",
    "        user_input = INPUT_WRAPPER.format(audio_path=audio_path, query=query)\n",
    "        dataset_to_write.append(\n",
    "            {\n",
    "                \"conversations\":\n",
    "                    [\n",
    "                        {\"from\": \"user\", \"value\": user_input},\n",
    "                        {\"from\": \"assistant\", \"value\": item[label_name]}\n",
    "                    ]\n",
    "            }\n",
    "        )\n",
    "\n",
    "    with open(dst_file, 'w', encoding='utf8') as f:\n",
    "        json.dump(dataset_to_write, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "make_dataset(\"data/slidespeech_30k_filtered_train_en_instruction.json\", \"data/slidespeech_30k_filtered_train/train.json\")\n",
    "make_dataset(\"data/slidespeech_30k_filtered_train_en_instruction_dev.json\", \"data/slidespeech_30k_filtered_train/dev.json\")\n",
    "make_dataset(\"data/slidespeech_30k_filtered_train_en_instruction_test.json\", \"data/slidespeech_30k_filtered_train/test.json\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "HOME_DIR = pathlib.Path(os.path.expanduser(\"~\"))\n",
    "\n",
    "def make_dataset(source_file, dst_file):\n",
    "    with open(source_file, 'r', encoding='utf8') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    # INSTRUCTION_PROMPT_WITH_KEYWORDS = \"\"\"请结合以下可能出现的关键词，做语音转文本。可能出现的关键词为：{keywords}\"\"\"\n",
    "    # INSTRUCTION_PROMPT_WITHOUT_KEYWORDS = \"\"\"语音转文本\"\"\"\n",
    "    INSTRUCTION_PROMPT_WITH_KEYWORDS = \"\"\"Transcibe speech to text according to keywords may appear in the utterance. Possible keywords are: {keywords}\"\"\"\n",
    "    INSTRUCTION_PROMPT_WITHOUT_KEYWORDS = \"\"\"Transcribe speech to text\"\"\"\n",
    "    # INSTRUCTION_PROMPT = \"\"\"Transcript Speech to Text: \"\"\"\n",
    "\n",
    "    INPUT_WRAPPER = \"\"\"<audio>{audio_path}</audio>{query}\"\"\"\n",
    "\n",
    "    if \"/data/rym/datasets/OpenSLR\" in data[0][\"audio_path\"]:\n",
    "        replace_path = \"/data/rym/datasets/OpenSLR\"\n",
    "    elif \"/nfs/speech/corpus/OpenSLR\" in data[0][\"audio_path\"]:\n",
    "        replace_path = \"/nfs/speech/corpus/OpenSLR\"\n",
    "    else:\n",
    "        raise ValueError(\"wrong input audio filepath\")\n",
    "\n",
    "    if \"text\" in data[0]:\n",
    "        label_name = \"text\"\n",
    "    elif \"transcript\" in data[0]:\n",
    "        label_name = \"transcript\"\n",
    "    else:\n",
    "        raise ValueError(\"wrong label name\")\n",
    "\n",
    "\n",
    "    dataset_to_write = []\n",
    "    for item in data:\n",
    "        keywords_lst = [s.lower() for s in item['keywords']]\n",
    "        if keywords_lst == [\"\"]:\n",
    "            query = INSTRUCTION_PROMPT_WITHOUT_KEYWORDS\n",
    "        else:\n",
    "            query = INSTRUCTION_PROMPT_WITH_KEYWORDS.format(keywords=', '.join(keywords_lst))\n",
    "        audio_path = item[\"audio_path\"].replace(replace_path, str(HOME_DIR / \"datasets/OpenSLR\"))\n",
    "        assert pathlib.Path(audio_path).exists()\n",
    "        user_input = INPUT_WRAPPER.format(audio_path=audio_path, query=query)\n",
    "        dataset_to_write.append(\n",
    "            {\n",
    "                \"conversations\":\n",
    "                    [\n",
    "                        {\"from\": \"user\", \"value\": user_input},\n",
    "                        {\"from\": \"assistant\", \"value\": item[label_name]}\n",
    "                    ]\n",
    "            }\n",
    "        )\n",
    "\n",
    "    with open(dst_file, 'w', encoding='utf8') as f:\n",
    "        json.dump(dataset_to_write, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "make_dataset(\"data/slidespeech_30k_filtered_train_en_instruction.json\", \"data/slidespeech_30k_filtered_train_en_instruction/train.json\")\n",
    "make_dataset(\"data/slidespeech_30k_filtered_train_en_instruction_dev.json\", \"data/slidespeech_30k_filtered_train_en_instruction/dev.json\")\n",
    "make_dataset(\"data/slidespeech_30k_filtered_train_en_instruction_test.json\", \"data/slidespeech_30k_filtered_train_en_instruction/test.json\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset type 2\n",
    "\n",
    "做关键词筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/slidespeech_30k.json\", 'r', encoding='utf8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "with open(\"data/context_filter/slidespeech_30k_filter_keywords.json\", 'r', encoding='utf8') as f:\n",
    "    filtered_data = json.load(f)\n",
    "    \n",
    "for i, item in enumerate(data):\n",
    "    if filtered_data[i][\"filtered_keywords\"] != [\"\"]:\n",
    "        item['keywords'] = filtered_data[i][\"filtered_keywords\"]\n",
    "    else:\n",
    "        item['keywords'] = [\"\"]\n",
    "    \n",
    "with open(\"data/slidespeech_30k_filtered_train_en_instruction.json\", 'w', encoding='utf8') as f:\n",
    "    json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "HOME_DIR = pathlib.Path(os.path.expanduser(\"~\"))\n",
    "\n",
    "def make_keywords_filter_dataset(source_file, dst_file):\n",
    "    with open(source_file, 'r', encoding='utf8') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    # INSTRUCTION_PROMPT = \"\"\"请结合以下可能出现的关键词，做语音转文本。可能出现的关键词为：{keywords}\"\"\"\n",
    "    # INSTRUCTION_PROMPT = \"\"\"Transcibe speech to text according to keywords may appear in the utterance. Possible key words are: {keywords}\"\"\"\n",
    "    # INSTRUCTION_PROMPT = \"\"\"Transcript Speech to Text: \"\"\"\n",
    "    INSTRUCTION_PROMPT = \"\"\"Select key words that may appear in the speech from the following keywords list: {keywords}\"\"\"\n",
    "\n",
    "    INPUT_WRAPPER = \"\"\"<audio>{audio_path}</audio>{query}\"\"\"\n",
    "\n",
    "    if \"/data/rym/datasets/OpenSLR\" in data[0][\"audio_path\"]:\n",
    "        replace_path = \"/data/rym/datasets/OpenSLR\"\n",
    "    elif \"/nfs/speech/corpus/OpenSLR\" in data[0][\"audio_path\"]:\n",
    "        replace_path = \"/nfs/speech/corpus/OpenSLR\"\n",
    "    else:\n",
    "        raise ValueError(\"wrong input audio filepath\")\n",
    "\n",
    "\n",
    "    dataset_to_write = []\n",
    "    for item in data:\n",
    "        keywords_lst = [s.lower() for s in item['keywords']]\n",
    "        query = INSTRUCTION_PROMPT.format(keywords=', '.join(keywords_lst))\n",
    "        audio_path = item[\"audio_path\"].replace(replace_path, str(HOME_DIR / \"datasets/OpenSLR\"))\n",
    "        assert pathlib.Path(audio_path).exists()\n",
    "        user_input = INPUT_WRAPPER.format(audio_path=audio_path, query=query)\n",
    "        dataset_to_write.append(\n",
    "            {\n",
    "                \"conversations\":\n",
    "                    [\n",
    "                        {\"from\": \"user\", \"value\": user_input},\n",
    "                        {\"from\": \"assistant\", \"value\": ', '.join(item[\"filtered_keywords\"]) if item[\"filtered_keywords\"] != [\"\"] else \"none\"}\n",
    "                    ]\n",
    "            }\n",
    "        )\n",
    "\n",
    "    with open(dst_file, 'w', encoding='utf8') as f:\n",
    "        json.dump(dataset_to_write, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "# make_keywords_filter_dataset(\"data/context_filter/slidespeech_30k_filter_keywords_test.json\", \"data/slidespeech_30k_filter_en_instruction/test.json\")\n",
    "# make_keywords_filter_dataset(\"data/context_filter/slidespeech_30k_filter_keywords_dev.json\", \"data/slidespeech_30k_filter_en_instruction/dev.json\")\n",
    "# make_keywords_filter_dataset(\"data/context_filter/slidespeech_30k_filter_keywords.json\", \"data/slidespeech_30k_filter_en_instruction/train.json\")\n",
    "    \n",
    "make_keywords_filter_dataset(\"data/context_filter/slidespeech_30k_filter_keywords_test.json\", \"data/slidespeech_L95_filter_en_instruction/test.json\")\n",
    "make_keywords_filter_dataset(\"data/context_filter/slidespeech_30k_filter_keywords_dev.json\", \"data/slidespeech_L95_filter_en_instruction/dev.json\")\n",
    "make_keywords_filter_dataset(\"data/context_filter/slidespeech_L95_filter_keywords.json\", \"data/slidespeech_L95_filter_en_instruction/train.json\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/slidespeech_L95_all.json\", 'r', encoding='utf8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "dataset_to_write = []\n",
    "for item in data:\n",
    "    filtered_keywords = []\n",
    "    for k in item[\"keywords\"]:\n",
    "        if k.lower() in item[\"transcript\"].split():\n",
    "            filtered_keywords.append(k.lower())\n",
    "    item[\"keywords\"] = [k.lower() for k in item[\"keywords\"]]\n",
    "    item[\"filtered_keywords\"] = filtered_keywords\n",
    "\n",
    "with open(\"data/context_filter/slidespeech_L95_filter_keywords.json\", 'w', encoding='utf8') as f:\n",
    "    json.dump(dataset_to_write, f,indent=2, ensure_ascii=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset type 3\n",
    "\n",
    "做关键词筛选+语音识别的多任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "HOME_DIR = pathlib.Path(os.path.expanduser(\"~\"))\n",
    "\n",
    "def make_keywords_filter_dataset(keywords_file, transcript_file, dst_file):\n",
    "    with open(keywords_file, 'r', encoding='utf8') as f:\n",
    "        kw_data = json.load(f)\n",
    "    with open(transcript_file, 'r', encoding='utf8') as f:\n",
    "        transcript_data = json.load(f)\n",
    "        \n",
    "    # INSTRUCTION_PROMPT = \"\"\"请结合以下可能出现的关键词，做语音转文本。可能出现的关键词为：{keywords}\"\"\"\n",
    "    # INSTRUCTION_PROMPT = \"\"\"Transcibe speech to text according to keywords may appear in the utterance. Possible key words are: {keywords}\"\"\"\n",
    "    # INSTRUCTION_PROMPT = \"\"\"Transcript Speech to Text: \"\"\"\n",
    "    # INSTRUCTION_PROMPT = \"\"\"Select key words that may appear in the speech from the following keywords list: {keywords}\"\"\"\n",
    "    INSTRUCTION_PROMPT = \"\"\"First select keywords that may appear in the speech from given keywords list. Then Transcribe speech to text according to selected keywords. Keywords are: {keywords}\"\"\"\n",
    "    RESPONSE_FORMAT = \"\"\"Selected keywords are: {keywords}.\\nTranscription: {transcript}\"\"\"\n",
    "    \n",
    "    INPUT_WRAPPER = \"\"\"<audio>{audio_path}</audio>{query}\"\"\"\n",
    "\n",
    "    if \"/data/rym/datasets/OpenSLR\" in kw_data[0][\"audio_path\"]:\n",
    "        replace_path = \"/data/rym/datasets/OpenSLR\"\n",
    "    elif \"/nfs/speech/corpus/OpenSLR\" in kw_data[0][\"audio_path\"]:\n",
    "        replace_path = \"/nfs/speech/corpus/OpenSLR\"\n",
    "    else:\n",
    "        raise ValueError(\"wrong input audio filepath\")\n",
    "\n",
    "    if \"text\" in transcript_data[0]:\n",
    "        label_name = \"text\"\n",
    "    elif \"transcript\" in data[0]:\n",
    "        label_name = \"transcript\"\n",
    "    else:\n",
    "        raise ValueError(\"wrong label name\")\n",
    "\n",
    "    dataset_to_write = []\n",
    "    for i in range(len(kw_data)):\n",
    "        kw_item = kw_data[i]\n",
    "        transcript_item = transcript_data[i]\n",
    "        keywords_lst = [s.lower() for s in kw_item['keywords']]\n",
    "        query = INSTRUCTION_PROMPT.format(keywords=', '.join(keywords_lst))\n",
    "        audio_path = kw_item[\"audio_path\"].replace(replace_path, str(HOME_DIR / \"datasets/OpenSLR\"))\n",
    "        assert pathlib.Path(audio_path).exists()\n",
    "        user_input = INPUT_WRAPPER.format(audio_path=audio_path, query=query)\n",
    "        filtered_keywords = ', '.join(kw_item[\"filtered_keywords\"]) if kw_item[\"filtered_keywords\"] != [\"\"] else \"none\"\n",
    "        label = RESPONSE_FORMAT.format(keywords=filtered_keywords, transcript=transcript_item[label_name])\n",
    "        dataset_to_write.append(\n",
    "            {\n",
    "                \"conversations\":\n",
    "                    [\n",
    "                        {\"from\": \"user\", \"value\": user_input},\n",
    "                        {\"from\": \"assistant\", \"value\": label}\n",
    "                    ]\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "    with open(dst_file, 'w', encoding='utf8') as f:\n",
    "        json.dump(dataset_to_write, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "# make_keywords_filter_dataset(\"data/context_filter/slidespeech_30k_filter_keywords_test.json\", \"data/slidespeech_30k_filter_en_instruction/test.json\")\n",
    "# make_keywords_filter_dataset(\"data/context_filter/slidespeech_30k_filter_keywords_dev.json\", \"data/slidespeech_30k_filter_en_instruction/dev.json\")\n",
    "# make_keywords_filter_dataset(\"data/context_filter/slidespeech_30k_filter_keywords.json\", \"data/slidespeech_30k_filter_en_instruction/train.json\")\n",
    "    \n",
    "make_keywords_filter_dataset(\"data/context_filter/slidespeech_30k_filter_keywords_test.json\", \"data/slidespeech_test.json\", \"data/slidespeech_30k_multitask_train_en_instruction/test.json\")\n",
    "make_keywords_filter_dataset(\"data/context_filter/slidespeech_30k_filter_keywords_dev.json\", \"data/slidespeech_dev.json\", \"data/slidespeech_30k_multitask_train_en_instruction/dev.json\")\n",
    "make_keywords_filter_dataset(\"data/context_filter/slidespeech_30k_filter_keywords.json\", \"data/slidespeech_30k.json\", \"data/slidespeech_30k_multitask_train_en_instruction/train.json\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import json\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    # 创建一个翻译表，用于移除所有标点符号\n",
    "    translator = str.maketrans('', '', ''.join(set(string.punctuation) - set(\"'\")))\n",
    "    # 使用translate方法移除标点符号\n",
    "    return text.translate(translator)\n",
    "\n",
    "def process_jsonl(input_file, output_file):\n",
    "    dataset_to_write = []\n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as f_in:\n",
    "        for line in f_in.readlines():\n",
    "            data_item = json.loads(line)\n",
    "            clean_text = remove_punctuation(data_item['text'])\n",
    "            data_item['text'] = clean_text\n",
    "            dataset_to_write.append(data_item)\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf8') as f_out:\n",
    "        json.dump(dataset_to_write, f_out, indent=2, ensure_ascii=False)\n",
    "            \n",
    "# 调用函数并传入文件路径\n",
    "# input_file_path = '/nfs/speech/yxzhang/modelscope-agent/modelscope-agent/slidespeech/workflow_test_3.jsonl'\n",
    "# output_file_path = '/nfs/speech/yxzhang/modelscope-agent/modelscope-agent/slidespeech/baseline_result/vasr_result/no_punc/workflow_test_3.txt'\n",
    "input_file_path = '/data/ymrong/Projects/ms-swift/data/slidespeech_dev.jsonl'\n",
    "output_file_path = '/data/ymrong/Projects/ms-swift/data/slidespeech_dev.json'\n",
    "process_jsonl(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pathlib\n",
    "import json\n",
    "import codecs\n",
    "import re\n",
    "\n",
    "\n",
    "def convert_jsonl_to_txt(result_file):\n",
    "    if isinstance(result_file, str):\n",
    "        result_file = pathlib.Path(result_file)\n",
    "    result_dir = result_file.parents[0]\n",
    "        \n",
    "    audio_paths = []\n",
    "    hyps = []\n",
    "    refs = []\n",
    "    with result_file.open(mode='rt', encoding='utf8') as f:\n",
    "        for line in f.readlines():\n",
    "            data_item = json.loads(line)\n",
    "            audio_paths.append(re.match(pattern=r\"<audio>(.*?)</audio>\", string=data_item[\"query\"]).group(1))\n",
    "            hyps.append(data_item[\"response\"])\n",
    "            refs.append(data_item[\"label\"])\n",
    "    \n",
    "    hyp_writer =  codecs.open(str(result_dir / \"test.hyp\"), mode='w', encoding='utf8')\n",
    "    ref_writer = codecs.open(str(result_dir / \"test.ref\"), mode='w', encoding='utf8')\n",
    "    for i, item in enumerate(audio_paths):\n",
    "        hyp_writer.write(f'{item} {hyps[i]}' + '\\n')\n",
    "        ref_writer.write(f'{item} {refs[i]}' + '\\n')\n",
    "        \n",
    "    hyp_writer.close()\n",
    "    ref_writer.close()\n",
    "\n",
    "result_file = pathlib.Path(\"/data/ymrong/output/qwen2-audio-7b-instruct/v11-20241011-105159/checkpoint-1450/infer_result/20241011-154337.jsonl\")\n",
    "convert_jsonl_to_txt(result_file)\n",
    "\n",
    "hyp_file = result_file.parents[0] / \"test.hyp\"\n",
    "ref_file = result_file.parents[0] / \"test.ref\"\n",
    "wer_file = result_file.parents[0] / \"test.wer\"\n",
    "import subprocess\n",
    "\n",
    "result = subprocess.run([\"python\", \"/data/ymrong/Projects/wenet/tools/compute-wer.py\", str(ref_file), str(hyp_file), \">\", str(wer_file)], capture_output=True, text=True)\n",
    "print(result.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import json\n",
    "import re\n",
    "\n",
    "def contains_chinese(text):\n",
    "    pattern = re.compile(r'[\\u4e00-\\u9fff]')\n",
    "    return bool(pattern.search(text))\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    # 创建一个翻译表，用于移除所有标点符号\n",
    "    translator = str.maketrans('', '', ''.join(set(string.punctuation) - set(\"'\")))\n",
    "    # 使用translate方法移除标点符号\n",
    "    return text.translate(translator)\n",
    "\n",
    "def process_jsonl(input_file, output_file):\n",
    "    dataset_to_write = []\n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as f_in:\n",
    "        for line in f_in.readlines():\n",
    "            data_item = json.loads(line)\n",
    "            clean_text = remove_punctuation(data_item['text'])\n",
    "            data_item['text'] = clean_text\n",
    "            dataset_to_write.append(data_item)\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf8') as f_out:\n",
    "        json.dump(dataset_to_write, f_out, indent=2, ensure_ascii=False)\n",
    "\n",
    "hyps = []\n",
    "refs = []\n",
    "wavs = []\n",
    "with open(\"qwen2-audio-instruct-result/20241014-214929.jsonl\", 'r', encoding='utf8') as f:\n",
    "    for line in f.readlines():\n",
    "        data_item = json.loads(line)\n",
    "        if contains_chinese(data_item[\"response\"]):\n",
    "            continue\n",
    "        if \"The transcript of the speech is:\" in data_item[\"response\"]:\n",
    "            hyp = data_item[\"response\"].split(\":\")[1]\n",
    "            hyp = remove_punctuation(hyp)\n",
    "            hyps.append(hyp.strip(\"' \"))\n",
    "            refs.append(data_item[\"label\"])\n",
    "            wavs.append(re.match(r\"<audio>(.*?)</audio>\", data_item[\"query\"]).group(1))\n",
    "\n",
    "with open(\"qwen2-audio-instruct-result/test.hyp\", 'w', encoding='utf8') as f:\n",
    "    for i, h in enumerate(hyps):\n",
    "        f.write(wavs[i] + '\\t' + h + '\\n')\n",
    "with open(\"qwen2-audio-instruct-result/test.ref\", 'w', encoding='utf8') as f:\n",
    "    for i, r in enumerate(refs):\n",
    "        f.write(wavs[i] + '\\t' + r + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ymrong/miniconda3/envs/swift/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:900: UserWarning: unknown class(es) [' 19th', ' 22', ' Zarina', ' acknowledge', ' afford', ' agd', ' alzheimers', ' antioppressive', ' applicable', ' beginning', ' built-in', ' bullying', ' ceded', ' chickpea', ' child', ' coachcurrent', ' colitis', ' come', ' copd', ' crossministerial', ' cyclists', ' defined', ' dietitian', ' draw', ' dsj', ' earlier', ' fcps', ' getting', ' goals', ' greater', ' hierarchal', ' howe', ' ibs', ' icce', ' identity', ' idm', ' iep', ' ieps', ' illegal', ' improvement', ' include', ' income', ' jinling', ' johannon', ' jon', ' khan', ' knowl', ' kris', ' lbd', ' let', ' letters', ' mallett', ' michelle', ' middle', ' mindlab', ' month', ' mother', ' mountain', ' multilevel', ' navigating', ' nearsighted', ' non', ' nut', ' ok', ' palus', ' pathological', ' paul', ' pm', ' practices', ' promoting', ' ptv', ' qr', ' regimen', ' researcher', ' rice', ' scratch', ' served', ' sight', ' skilled', ' sms', ' srl', ' stream', ' tdp', ' throughthe', ' tivas', ' tofu', ' tv', ' ulcerative', ' vegan', ' wait', ' weigh', ' wheat', ' worsening', ' wsu', 'ability', 'adaptive', 'additional', 'adopt', 'alzheimers', 'analytics', 'apa', 'assessments', 'autism', 'autoimmune', 'batteries', 'birthday', 'boundless', 'cheese', 'chronicle', 'compliant', 'computer', 'contains', 'cycling', 'demented', 'demo', 'deployments', 'diagnoses', 'different', 'disciples', 'educational', 'farmers', 'fcps', 'feel', 'forest', 'free', 'frittatas', 'fryer', 'fun', 'ganzalez', 'gilded', 'gluten', 'gordon', 'great', 'icce', 'instagram', 'instructors', 'interested', 'items', 'jerry', 'jiquing', 'juices', 'laughter', 'laurine', 'lines', 'manufacturing', 'mark', 'moderate', 'moderator', 'nearsightedness', 'new', 'nsf', 'nutrients', 'ocr', 'okay', 'ophthalmology', 'oppressive', 'political', 'posters', 'protection', 'rand', 'relevant', 'requirements', 'rinsing', 'running', 'schools', 'separately', 'shaping', 'soyfree', 'utc', 'vips', 'wired', 'woman', 'word', 'wsu', 'yuan', 'zhejiang'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Precision: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9504010476346374</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Precision: \u001b[1;36m0.9504010476346374\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Recall: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9116030774061862</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Recall: \u001b[1;36m0.9116030774061862\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">F1 Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.930597852219907</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "F1 Score: \u001b[1;36m0.930597852219907\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import json\n",
    "\n",
    "labels = []\n",
    "preds = []\n",
    "with open(\"/data/ymrong/output/slidespeech_30k_filter_lora_en_instruction/qwen2-audio-7b-instruct/v6-20241021-112621/checkpoint-449-merged/infer_result/20241021-122310.jsonl\", 'r', encoding='utf8') as f:\n",
    "    for line in f.readlines():\n",
    "        l = json.loads(line)\n",
    "        labels.append(l['label'])\n",
    "        preds.append(l['response'])\n",
    "        \n",
    "labels = [item.split(',') for item in labels]\n",
    "preds = [item.split(',') for item in preds]\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_true = mlb.fit_transform(labels)\n",
    "y_pred = mlb.transform(preds)\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average='micro')\n",
    "recall = recall_score(y_true, y_pred, average='micro')\n",
    "f1 = f1_score(y_true, y_pred, average='micro')\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
